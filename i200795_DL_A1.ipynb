{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Library"
      ],
      "metadata": {
        "id": "ru_10jai3Lif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7udqpBB3Jbr",
        "outputId": "fe16e78c-a4a9-4372-c9bd-7684e9ce8e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Dataset"
      ],
      "metadata": {
        "id": "gNdcSYFT3w9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "zip_file = 'flights_data.zip'\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall('flights_data')\n",
        "\n",
        "\n",
        "os.listdir('flights_data')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw6_m1jw3fMd",
        "outputId": "9c3cbcd1-08cd-4107-98e4-6b6df6a60469"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Flights Data']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Files"
      ],
      "metadata": {
        "id": "_wFbwVxL3y3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "\n",
        "\n",
        "def read_docx_file(filepath):\n",
        "    doc = Document(filepath)\n",
        "    return '\\n'.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "\n",
        "def parse_json_from_docx(directory):\n",
        "    data = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.docx'):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            doc_text = read_docx_file(filepath)\n",
        "            try:\n",
        "\n",
        "                json_data = json.loads(doc_text)\n",
        "                data.extend(json_data)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON in file {filename}: {e}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "data_directory = 'flights_data/Flights Data'\n",
        "raw_data = parse_json_from_docx(data_directory)\n",
        "\n",
        "\n",
        "df = pd.json_normalize(raw_data)\n",
        "\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDiA_tq93ylC",
        "outputId": "0ef16fcc-6847-4c71-8d42-fbcec066eb49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        type  status departure.iataCode departure.icaoCode departure.terminal  \\\n",
            "0  departure  active                lhe               opla                  m   \n",
            "1  departure  active                lhe               opla                  m   \n",
            "2  departure  active                lhe               opla                  m   \n",
            "3  departure  active                lhe               opla                  m   \n",
            "4  departure  active                lhe               opla                NaN   \n",
            "\n",
            "   departure.scheduledTime  departure.estimatedTime arrival.iataCode  \\\n",
            "0  2023-08-01t08:00:00.000  2023-08-01t08:00:00.000              jed   \n",
            "1  2023-08-01t09:00:00.000  2023-08-01t09:00:00.000              khi   \n",
            "2  2023-08-01t09:10:00.000                      NaN              jed   \n",
            "3  2023-08-01t09:15:00.000  2023-08-01t09:21:00.000              uet   \n",
            "4  2023-08-01t09:50:00.000  2023-08-01t09:50:00.000              urc   \n",
            "\n",
            "  arrival.icaoCode arrival.terminal  ... codeshared.airline.iataCode  \\\n",
            "0             oejn                h  ...                         NaN   \n",
            "1             opkc                m  ...                         NaN   \n",
            "2             oejn              NaN  ...                         NaN   \n",
            "3             opqt              NaN  ...                         NaN   \n",
            "4             zwww                3  ...                         NaN   \n",
            "\n",
            "  codeshared.airline.icaoCode codeshared.flight.number  \\\n",
            "0                         NaN                      NaN   \n",
            "1                         NaN                      NaN   \n",
            "2                         NaN                      NaN   \n",
            "3                         NaN                      NaN   \n",
            "4                         NaN                      NaN   \n",
            "\n",
            "  codeshared.flight.iataNumber codeshared.flight.icaoNumber departure.gate  \\\n",
            "0                          NaN                          NaN            NaN   \n",
            "1                          NaN                          NaN            NaN   \n",
            "2                          NaN                          NaN            NaN   \n",
            "3                          NaN                          NaN            NaN   \n",
            "4                          NaN                          NaN            NaN   \n",
            "\n",
            "  arrival.gate  arrival.actualTime arrival.estimatedRunway  \\\n",
            "0          NaN                 NaN                     NaN   \n",
            "1          NaN                 NaN                     NaN   \n",
            "2          NaN                 NaN                     NaN   \n",
            "3          NaN                 NaN                     NaN   \n",
            "4          NaN                 NaN                     NaN   \n",
            "\n",
            "  arrival.actualRunway  \n",
            "0                  NaN  \n",
            "1                  NaN  \n",
            "2                  NaN  \n",
            "3                  NaN  \n",
            "4                  NaN  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing Values"
      ],
      "metadata": {
        "id": "zQfzCF0O5ucP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['departure.delay'] = df['departure.delay'].fillna(df['departure.delay'].median())\n",
        "\n",
        "\n",
        "categorical_columns = ['departure.terminal', 'arrival.terminal', 'airline.name', 'flight.number',\n",
        "                       'codeshared.airline.name', 'codeshared.flight.number']\n",
        "for col in categorical_columns:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna('Unknown')\n"
      ],
      "metadata": {
        "id": "URsDs8uv5uzr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['departure.scheduledTime'] = pd.to_datetime(df['departure.scheduledTime'], errors='coerce')\n",
        "df['departure.estimatedTime'] = pd.to_datetime(df['departure.estimatedTime'], errors='coerce')\n",
        "\n",
        "\n",
        "df['delay_minutes'] = (df['departure.estimatedTime'] - df['departure.scheduledTime']).dt.total_seconds() / 60\n",
        "\n",
        "\n",
        "df['delay_minutes'] = df['delay_minutes'].fillna(0)\n"
      ],
      "metadata": {
        "id": "DhUgmL8h5xzv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['delay_bin'] = pd.qcut(df['delay_minutes'], 8, labels=False, duplicates='drop')\n",
        "\n",
        "\n",
        "print(df[['delay_minutes', 'delay_bin']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPb_aMhm5yQP",
        "outputId": "566af964-2681-491a-d628-caecb9d09ad6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   delay_minutes  delay_bin\n",
            "0            0.0          0\n",
            "1            0.0          0\n",
            "2            0.0          0\n",
            "3            6.0          1\n",
            "4            0.0          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "QSsCWNzj6Jva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class LogisticRegressionOVR:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.classes = None\n",
        "        self.weights = {}\n",
        "        self.bias = {}\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        for cls in self.classes:\n",
        "            y_binary = np.where(y == cls, 1, 0)\n",
        "            w = np.zeros(X.shape[1])\n",
        "            b = 0\n",
        "            for _ in range(self.epochs):\n",
        "                linear_model = np.dot(X, w) + b\n",
        "                y_pred = self.sigmoid(linear_model)\n",
        "                dw = np.dot(X.T, (y_pred - y_binary)) / len(y_binary)\n",
        "                db = np.sum(y_pred - y_binary) / len(y_binary)\n",
        "                w -= self.learning_rate * dw\n",
        "                b -= self.learning_rate * db\n",
        "            self.weights[cls] = w\n",
        "            self.bias[cls] = b\n",
        "\n",
        "    def predict(self, X):\n",
        "        probabilities = {}\n",
        "        for cls in self.classes:\n",
        "            linear_model = np.dot(X, self.weights[cls]) + self.bias[cls]\n",
        "            probabilities[cls] = self.sigmoid(linear_model)\n",
        "        predictions = np.argmax(list(probabilities.values()), axis=0)\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "VfR1e9-76L3n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "Vo0PLJWO6QTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeNode:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=5, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _gini(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        impurity = 1 - sum((count / len(y)) ** 2 for count in counts)\n",
        "        return impurity\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gini = 1\n",
        "        best_feature, best_threshold = None, None\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        for feature in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                left_idxs = X[:, feature] < threshold\n",
        "                right_idxs = X[:, feature] >= threshold\n",
        "                if len(y[left_idxs]) == 0 or len(y[right_idxs]) == 0:\n",
        "                    continue\n",
        "                gini_left = self._gini(y[left_idxs])\n",
        "                gini_right = self._gini(y[right_idxs])\n",
        "                gini = (len(y[left_idxs]) / len(y)) * gini_left + (len(y[right_idxs]) / len(y)) * gini_right\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        if (depth >= self.max_depth or num_samples < self.min_samples_split or len(np.unique(y)) == 1):\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return DecisionTreeNode(value=leaf_value)\n",
        "\n",
        "        feature, threshold = self._best_split(X, y)\n",
        "        if feature is None:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return DecisionTreeNode(value=leaf_value)\n",
        "\n",
        "        left_idxs = X[:, feature] < threshold\n",
        "        right_idxs = X[:, feature] >= threshold\n",
        "        left = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
        "        right = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
        "        return DecisionTreeNode(feature, threshold, left, right)\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        return np.bincount(y).argmax()\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "        if x[node.feature] < node.threshold:\n",
        "            return self._traverse_tree(x, node.left)\n",
        "        return self._traverse_tree(x, node.right)\n"
      ],
      "metadata": {
        "id": "yebkFvc06O8S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "OCIBg_B_6S3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM:\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000, kernel='linear'):\n",
        "        self.lr = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.kernel = kernel\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.kernel_function = self._linear_kernel if kernel == 'linear' else None\n",
        "\n",
        "    def _linear_kernel(self, x1, x2):\n",
        "        return np.dot(x1, x2)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                condition = y_[idx] * (np.dot(x_i, self.weights) - self.bias) >= 1\n",
        "                if condition:\n",
        "                    self.weights -= self.lr * (2 * self.lambda_param * self.weights)\n",
        "                else:\n",
        "                    self.weights -= self.lr * (2 * self.lambda_param * self.weights - np.dot(x_i, y_[idx]))\n",
        "                    self.bias -= self.lr * y_[idx]\n",
        "\n",
        "    def predict(self, X):\n",
        "        approx = np.dot(X, self.weights) - self.bias\n",
        "        return np.sign(approx)\n"
      ],
      "metadata": {
        "id": "zlQ894HP6Tc1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble"
      ],
      "metadata": {
        "id": "H8jrVOr06WU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StackingEnsemble:\n",
        "    def __init__(self, base_models, meta_model):\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        for model in self.base_models:\n",
        "            model.fit(X, y)\n",
        "\n",
        "\n",
        "        meta_features = np.column_stack([model.predict(X) for model in self.base_models])\n",
        "\n",
        "\n",
        "        self.meta_model.fit(meta_features, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([model.predict(X) for model in self.base_models])\n",
        "        return self.meta_model.predict(meta_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "6xBQ5noe6Xye"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Creation"
      ],
      "metadata": {
        "id": "knbOngd-01Pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df.drop(columns=['delay_bin'])\n",
        "y = df['delay_bin']\n",
        "X = X.select_dtypes(include=[np.number]).fillna(0)\n",
        "\n",
        "\n",
        "def train_test_split_manual(X, y, test_size=0.2):\n",
        "\n",
        "    np.random.seed(42)\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "\n",
        "    split_idx = int(X.shape[0] * (1 - test_size))\n",
        "\n",
        "\n",
        "    X_train, X_test = X.iloc[indices[:split_idx]], X.iloc[indices[split_idx:]]\n",
        "    y_train, y_test = y.iloc[indices[:split_idx]], y.iloc[indices[split_idx:]]\n",
        "\n",
        "    return X_train.values, X_test.values, y_train.values, y_test.values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split_manual(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "BHPL0zXB01Ct"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression Training"
      ],
      "metadata": {
        "id": "wolJHhWX1Oaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_lr = LogisticRegressionOVR(learning_rate=0.01, epochs=500)\n",
        "model_lr.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Jj9QVx1Noe",
        "outputId": "f8f13249-c2f3-4c2c-a7d9-45b3f3b86ddf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-dbe4182987db>:12: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Training"
      ],
      "metadata": {
        "id": "jWHzkNwf1TcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_dt = DecisionTree(max_depth=5, min_samples_split=2)\n",
        "model_dt.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Rw_tUO-_1UT6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Training"
      ],
      "metadata": {
        "id": "o1H_b_X_1XYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_svm = SVM(learning_rate=0.001, lambda_param=0.01, n_iters=200, kernel='linear')\n",
        "model_svm.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "C2GCej8x1X-D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble Training"
      ],
      "metadata": {
        "id": "J1Ke2_pf1alQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "meta_model = LogisticRegressionOVR(learning_rate=0.01, epochs=500)\n",
        "\n",
        "\n",
        "ensemble = StackingEnsemble(base_models=[model_lr, model_dt, model_svm], meta_model=meta_model)\n",
        "ensemble.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-omVhNa1b5C",
        "outputId": "206ad2f2-cbd5-4855-e982-0339b05b88cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-dbe4182987db>:12: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "j2vYsf8a1_Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "\n",
        "def compute_f1_score(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    f1_total = 0\n",
        "    for cls in classes:\n",
        "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
        "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
        "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
        "        f1_total += f1\n",
        "    return f1_total / len(classes)\n",
        "\n",
        "\n",
        "accuracy = compute_accuracy(y_test, y_pred)\n",
        "f1 = compute_f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e_iqQN-2AYG",
        "outputId": "5bd03ce7-22e4-4db9-8d97-ccba0bc0ed3a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9007924319675655\n",
            "F1-Score: 0.5745893976819519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-dbe4182987db>:12: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus"
      ],
      "metadata": {
        "id": "jSEsxeps5-YJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "xE-ioaDH6E0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.class_priors = {}\n",
        "        self.feature_stats = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        for cls in self.classes:\n",
        "            X_cls = X[y == cls]\n",
        "            self.class_priors[cls] = len(X_cls) / len(X)\n",
        "            self.feature_stats[cls] = {\n",
        "                'mean': np.mean(X_cls, axis=0),\n",
        "                'var': np.var(X_cls, axis=0)\n",
        "            }\n",
        "\n",
        "    def gaussian_pdf(self, x, mean, var):\n",
        "        eps = 1e-6\n",
        "        coef = 1.0 / np.sqrt(2.0 * np.pi * var + eps)\n",
        "        exponent = np.exp(-(x - mean) ** 2 / (2 * var + eps))\n",
        "        return coef * exponent\n",
        "\n",
        "    def predict(self, X):\n",
        "        posteriors = []\n",
        "        for x in X:\n",
        "            class_posteriors = []\n",
        "            for cls in self.classes:\n",
        "                prior = np.log(self.class_priors[cls])\n",
        "                likelihood = np.sum(np.log(self.gaussian_pdf(x, self.feature_stats[cls]['mean'], self.feature_stats[cls]['var'])))\n",
        "                class_posteriors.append(prior + likelihood)\n",
        "            posteriors.append(self.classes[np.argmax(class_posteriors)])\n",
        "        return np.array(posteriors)\n",
        "\n"
      ],
      "metadata": {
        "id": "6hzpvOQR5_br"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes Training"
      ],
      "metadata": {
        "id": "w_M71AVf6DTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_nb = NaiveBayes()\n",
        "model_nb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "WbED0cj86HPQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Ensemble Training"
      ],
      "metadata": {
        "id": "iDCmuDgV6Qu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "meta_model = LogisticRegressionOVR(learning_rate=0.01, epochs=500)\n",
        "\n",
        "\n",
        "ensemble = StackingEnsemble(base_models=[model_lr, model_dt, model_svm, model_nb], meta_model=meta_model)\n",
        "ensemble.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okp4hGu_6SPf",
        "outputId": "56bc193c-0599-4c89-e2ac-47399d260b7e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-dbe4182987db>:12: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-25-2303dde67c91>:30: RuntimeWarning: divide by zero encountered in log\n",
            "  likelihood = np.sum(np.log(self.gaussian_pdf(x, self.feature_stats[cls]['mean'], self.feature_stats[cls]['var'])))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Ensemble Evaluation"
      ],
      "metadata": {
        "id": "ympynnSn6T_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = compute_accuracy(y_test, y_pred)\n",
        "f1 = compute_f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ-_N_e26X-V",
        "outputId": "122c60b2-fb91-4afa-879e-5f20056c3499"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-dbe4182987db>:12: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n",
            "<ipython-input-25-2303dde67c91>:30: RuntimeWarning: divide by zero encountered in log\n",
            "  likelihood = np.sum(np.log(self.gaussian_pdf(x, self.feature_stats[cls]['mean'], self.feature_stats[cls]['var'])))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9007924319675655\n",
            "F1-Score: 0.5745893976819519\n"
          ]
        }
      ]
    }
  ]
}